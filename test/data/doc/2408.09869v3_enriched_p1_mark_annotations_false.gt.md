# Docling Technical Report

In this image we can see a cartoon image of a duck holding a paper.

<!-- image -->

In this image we can see a cartoon image of a duck holding a paper.

Version 1.0

Christoph Auer Maksym Lysak Ahmed Nassar Michele Dolfi Nikolaos Livathinos Panos Vagenas Cesar Berrospi Ramis Matteo Omenetti Fabian Lindlbauer Kasper Dinkla Lokesh Mishra Yusik Kim Shubham Gupta Rafael Teixeira de Lima Valery Weber Lucas Morin Ingmar Meijer Viktor Kuropiatnyk Peter W. J. Staar

AI4K Group, IBM Research RÂ¨ uschlikon, Switzerland

## Abstract

This technical report introduces Docling , an easy to use, self-contained, MITlicensed open-source package for PDF document conversion. It is powered by state-of-the-art specialized AI models for layout analysis (DocLayNet) and table structure recognition (TableFormer), and runs efficiently on commodity hardware in a small resource budget. The code interface allows for easy extensibility and addition of new features and models.

## 1 Introduction

Converting PDF documents back into a machine-processable format has been a major challenge for decades due to their huge variability in formats, weak standardization and printing-optimized characteristic, which discards most structural features and metadata. With the advent of LLMs and popular application patterns such as retrieval-augmented generation (RAG), leveraging the rich content embedded in PDFs has become ever more relevant. In the past decade, several powerful document understanding solutions have emerged on the market, most of which are commercial software, cloud offerings [3] and most recently, multi-modal vision-language models. As of today, only a handful of open-source tools cover PDF conversion, leaving a significant feature and quality gap to proprietary solutions.

With Docling , we open-source a very capable and efficient document conversion tool which builds on the powerful, specialized AI models and datasets for layout analysis and table structure recognition we developed and presented in the recent past [12, 13, 9]. Docling is designed as a simple, self-contained python library with permissive license, running entirely locally on commodity hardware. Its code architecture allows for easy extensibility and addition of new features and models.

In this image, we can see some text and images.

torch runtimes backing the Docling pipeline. We will deliver updates on this topic at in a future version of this report.

summary: Typical Docling setup runtime characterization.
type: performance data

Table 1: Runtime characteristics of Docling with the standard model pipeline and settings, on our test dataset of 225 pages, on two different systems. OCR is disabled. We show the time-to-solution (TTS), computed throughput in pages per second, and the peak memory used (resident set size) for both the Docling-native PDF backend and for the pypdfium backend, using 4 and 16 threads.

| CPU                              | Thread budget   | native backend   | native backend   | native backend   | pypdfium backend   | pypdfium backend   | pypdfium backend   |
|----------------------------------|-----------------|------------------|------------------|------------------|--------------------|--------------------|--------------------|
|                                  |                 | TTS              | Pages/s          | Mem              | TTS                | Pages/s            | Mem                |
| Apple M3 Max                     | 4               | 177 s 167 s      | 1.27 1.34        | 6.20 GB          | 103 s 92 s         | 2.18 2.45          | 2.56 GB            |
| (16 cores) Intel(R) Xeon E5-2690 | 16 4 16         | 375 s 244 s      | 0.60 0.92        | 6.16 GB          | 239 s 143 s        | 0.94 1.57          | 2.42 GB            |

{'summary': 'Typical Docling setup runtime characterization.', 'type': 'performance data'}

## 5 Applications

Thanks to the high-quality, richly structured document conversion achieved by Docling, its output qualifies for numerous downstream applications. For example, Docling can provide a base for detailed enterprise document search, passage retrieval or classification use-cases, or support knowledge extraction pipelines, allowing specific treatment of different structures in the document, such as tables, figures, section structure or references. For popular generative AI application patterns, such as retrieval-augmented generation (RAG), we provide quackling , an open-source package which capitalizes on Docling's feature-rich document output to enable document-native optimized vector embedding and chunking. It plugs in seamlessly with LLM frameworks such as LlamaIndex [8]. Since Docling is fast, stable and cheap to run, it also makes for an excellent choice to build document-derived datasets. With its powerful table structure recognition, it provides significant benefit to automated knowledge-base construction [11, 10]. Docling is also integrated within the open IBM data prep kit [6], which implements scalable data transforms to build large-scale multi-modal training datasets.

## 6 Future work and contributions

Docling is designed to allow easy extension of the model library and pipelines. In the future, we plan to extend Docling with several more models, such as a figure-classifier model, an equationrecognition model, a code-recognition model and more. This will help improve the quality of conversion for specific types of content, as well as augment extracted document metadata with additional information. Further investment into testing and optimizing GPU acceleration as well as improving the Docling-native PDF backend are on our roadmap, too.

We encourage everyone to propose or implement additional features and models, and will gladly take your inputs and contributions under review . The codebase of Docling is open for use and contribution, under the MIT license agreement and in alignment with our contributing guidelines included in the Docling repository. If you use Docling in your projects, please consider citing this technical report.

## References

- [1] J. AI. Easyocr: Ready-to-use ocr with 80+ supported languages. https://github.com/ JaidedAI/EasyOCR , 2024. Version: 1.7.0.
- [2] J. Ansel, E. Yang, H. He, N. Gimelshein, A. Jain, M. Voznesensky, B. Bao, P. Bell, D. Berard, E. Burovski, G. Chauhan, A. Chourdia, W. Constable, A. Desmaison, Z. DeVito, E. Ellison, W. Feng, J. Gong, M. Gschwind, B. Hirsh, S. Huang, K. Kalambarkar, L. Kirsch, M. Lazos, M. Lezcano, Y. Liang, J. Liang, Y. Lu, C. Luk, B. Maher, Y. Pan, C. Puhrsch, M. Reso, M. Saroufim, M. Y. Siraichi, H. Suk, M. Suo, P. Tillet, E. Wang, X. Wang, W. Wen, S. Zhang, X. Zhao, K. Zhou, R. Zou, A. Mathews, G. Chanan, P. Wu, and S. Chintala. Pytorch 2: Faster

In this image there is a table with some text on it.

In this image we can see a text.

In this image I can see the cover of the book.

In this image there is a paper with some text on it.

In this image, we can see a table with some text.

The image is a line graph that shows the percentage of respondents who have completed a certain training program over a period of time. The x-axis represents the percentage of respondents, ranging from 0% to 70%. The y-axis represents the percentage of respondents, ranging from 0% to 70%. The graph shows a trend of increasing the percentage of respondents who have completed the training program over time.

The graph has two lines: one for the training program and one for the percentage of respondents who have completed the training program. The line for the training program is shown to be increasing, while the line for the percentage of respondents who have completed the training program is decreasing.

### Analysis:

#### Training Program:
- **Initial Data**: The graph shows a general increase in the percentage of respondents who have completed the training program.
- **Peak**: The peak in the percentage of respondents who have completed the training program is around 70%.

The image is a flat, two-dimensional representation of a letter "A" on a blue circle. The letter "A" is positioned in the center of the circle. The circle has a smooth, gradient background that transitions from a lighter blue at the top to a darker blue at the bottom. The gradient effect gives the letter "A" a three-dimensional appearance, making it appear three-dimensional.

The letter "A" is white, which is the standard color used for the letter "A" in many languages. The letter "A" is a capital letter, and it is positioned in the center of the circle. The circle itself is a simple, flat shape, which is often used in digital art and design to create a clean and simple design.

The background of the circle is a gradient, transitioning from a lighter blue at the top to a darker blue at the bottom. This gradient effect creates a sense of depth and dimension, making the letter "A"

In this image, there is a table with two columns. The first column is labeled "Class label," and the second column is labeled "Count." The first row in the table has the label "Class label," and the count is 22524. The second row in the table has the label "Count," and the count is 6318.

In this image I can see a blue circle.

A table with different columns and rows.

In this image there is a text in the middle.
